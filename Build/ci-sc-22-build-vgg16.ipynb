{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Modules**","metadata":{}},{"cell_type":"code","source":"# TF --> TPU environment version\n!pip install -U tensorflow==2.4.1","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:25:50.124054Z","iopub.execute_input":"2021-12-24T22:25:50.125085Z","iopub.status.idle":"2021-12-24T22:27:10.133850Z","shell.execute_reply.started":"2021-12-24T22:25:50.125024Z","shell.execute_reply":"2021-12-24T22:27:10.132973Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.4.1\n  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n     |████████████████████████████████| 394.3 MB 7.2 kB/s               |██████████████▏                 | 174.0 MB 18.1 MB/s eta 0:00:13\n\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.15.0)\nCollecting h5py~=2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n     |████████████████████████████████| 2.9 MB 40.4 MB/s            \n\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\nCollecting typing-extensions~=3.7.4\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n     |████████████████████████████████| 3.8 MB 52.4 MB/s            \n\u001b[?25hCollecting six~=1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\nCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\nCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.19.1)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\nCollecting tensorflow-estimator<2.5.0,>=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n     |████████████████████████████████| 462 kB 35.3 MB/s            \n\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.2)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (59.1.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.7)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.6.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\nBuilding wheels for collected packages: wrapt\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=77049 sha256=6e0e5170eadfe435140aacd208cdf42a449c7b3985314f8c5aeaa9cf5e770944\n  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built wrapt\nInstalling collected packages: typing-extensions, six, grpcio, wrapt, tensorflow-estimator, h5py, gast, tensorflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.2\n    Uninstalling typing-extensions-3.10.0.2:\n      Successfully uninstalled typing-extensions-3.10.0.2\n  Attempting uninstall: six\n    Found existing installation: six 1.16.0\n    Uninstalling six-1.16.0:\n      Successfully uninstalled six-1.16.0\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.42.0\n    Uninstalling grpcio-1.42.0:\n      Successfully uninstalled grpcio-1.42.0\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.13.3\n    Uninstalling wrapt-1.13.3:\n      Successfully uninstalled wrapt-1.13.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.1.0\n    Uninstalling h5py-3.1.0:\n      Successfully uninstalled h5py-3.1.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.4.0\n    Uninstalling gast-0.4.0:\n      Successfully uninstalled gast-0.4.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.2\n    Uninstalling tensorflow-2.6.2:\n      Successfully uninstalled tensorflow-2.6.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nexplainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\nbeatrix-jupyterlab 3.1.4 requires google-cloud-bigquery-storage, which is not installed.\ntfx-bsl 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\ntfx-bsl 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\ntfx-bsl 1.4.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<3,>=1.15.2, but you have tensorflow 2.4.1 which is incompatible.\ntensorflow-transform 1.4.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\ntensorflow-transform 1.4.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.0 which is incompatible.\ntensorflow-transform 1.4.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,<2.7,>=1.15.2, but you have tensorflow 2.4.1 which is incompatible.\ntensorflow-serving-api 2.6.1 requires tensorflow<3,>=2.6.1, but you have tensorflow 2.4.1 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.4.1 which is incompatible.\noptax 0.1.0 requires typing-extensions~=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\ngrpcio-status 1.42.0 requires grpcio>=1.42.0, but you have grpcio 1.32.0 which is incompatible.\ngcsfs 2021.11.0 requires fsspec==2021.11.0, but you have fsspec 2021.11.1 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.8.2 which is incompatible.\ncloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.8 which is incompatible.\nbokeh 2.4.2 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\nblack 21.10b0 requires typing-extensions>=3.10.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\napache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\napache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.0 which is incompatible.\naiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.23.15 which is incompatible.\u001b[0m\nSuccessfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 six-1.15.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\n\nimport os\n\nimport copy\n\nimport warnings\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nsys.path.insert(0, '../input/deeplearning-utils')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:10.135988Z","iopub.execute_input":"2021-12-24T22:27:10.136383Z","iopub.status.idle":"2021-12-24T22:27:10.151264Z","shell.execute_reply.started":"2021-12-24T22:27:10.136275Z","shell.execute_reply":"2021-12-24T22:27:10.149634Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# from utils.external.common import Reader\n\nfrom utils.tf.ops import io","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:10.153096Z","iopub.execute_input":"2021-12-24T22:27:10.153340Z","iopub.status.idle":"2021-12-24T22:27:13.741855Z","shell.execute_reply.started":"2021-12-24T22:27:10.153288Z","shell.execute_reply":"2021-12-24T22:27:13.740960Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:13.744293Z","iopub.execute_input":"2021-12-24T22:27:13.745083Z","iopub.status.idle":"2021-12-24T22:27:13.750773Z","shell.execute_reply.started":"2021-12-24T22:27:13.745028Z","shell.execute_reply":"2021-12-24T22:27:13.749679Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras import backend, optimizers, regularizers\n\nfrom tensorflow.keras.layers import *\n\nfrom tensorflow.keras.models import Sequential, Model\n\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:13.752127Z","iopub.execute_input":"2021-12-24T22:27:13.752407Z","iopub.status.idle":"2021-12-24T22:27:16.490328Z","shell.execute_reply.started":"2021-12-24T22:27:13.752374Z","shell.execute_reply":"2021-12-24T22:27:16.489388Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Config**","metadata":{}},{"cell_type":"code","source":"class Config:\n    \n    name = 'vgg16'\n    \n    IMAGE_SIZE = (224, 224, 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:16.491699Z","iopub.execute_input":"2021-12-24T22:27:16.492050Z","iopub.status.idle":"2021-12-24T22:27:16.504851Z","shell.execute_reply.started":"2021-12-24T22:27:16.492014Z","shell.execute_reply":"2021-12-24T22:27:16.503771Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **Build Model**","metadata":{}},{"cell_type":"code","source":"def adjust_name(name):\n    \n    if name is None:\n    \n        name = ''\n    \n    else:\n        \n        name = name + '_'\n        \n    return name","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:16.506030Z","iopub.execute_input":"2021-12-24T22:27:16.506424Z","iopub.status.idle":"2021-12-24T22:27:16.517080Z","shell.execute_reply.started":"2021-12-24T22:27:16.506390Z","shell.execute_reply":"2021-12-24T22:27:16.516017Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def conv2d_block(inputs, filters, use_conv3=False, name=None):\n    \n    name = adjust_name(name)\n     \n    kernel_size = (3, 3)\n    \n    z = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', name=f'{name}conv1')(inputs)\n    z = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', name=f'{name}conv2')(z)\n    \n    if use_conv3:\n        \n        z = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', name=f'{name}conv3')(z)\n    \n    z = MaxPooling2D((2, 2), strides=(2, 2), name=f'{name}pool')(z)\n    \n    return z","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:16.520416Z","iopub.execute_input":"2021-12-24T22:27:16.520731Z","iopub.status.idle":"2021-12-24T22:27:16.529740Z","shell.execute_reply.started":"2021-12-24T22:27:16.520693Z","shell.execute_reply":"2021-12-24T22:27:16.528757Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_blocks(inputs):\n    \n    # 1\n    z = conv2d_block(inputs, 64, use_conv3=False, name='block1')\n\n    # 2\n    z = conv2d_block(z, 128, use_conv3=False, name='block2')\n\n    # 3\n    z = conv2d_block(z, 256, use_conv3=True, name='block3')\n\n    # 4\n    z = conv2d_block(z, 512, use_conv3=True, name='block4')\n\n    # 5\n    z = conv2d_block(z, 512, use_conv3=True, name='block5')\n    \n    return z","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:16.530844Z","iopub.execute_input":"2021-12-24T22:27:16.531079Z","iopub.status.idle":"2021-12-24T22:27:16.543267Z","shell.execute_reply.started":"2021-12-24T22:27:16.531051Z","shell.execute_reply":"2021-12-24T22:27:16.542350Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def top_block(inputs, num_classes, dropout_rate=None):\n    \n    z = Flatten(name='flatten')(inputs)\n    \n    z = Dense(4096, activation='relu', name='fc1')(z)\n    \n    if dropout_rate is not None:\n        \n        z = Dropout(dropout_rate)(z)\n    \n    z = Dense(4096, activation='relu', name='fc2')(z)\n    \n    if dropout_rate is not None:\n        \n        z = Dropout(dropout_rate)(z)\n        \n    y = Dense(num_classes, activation='softmax', name='predictions')(z)\n    \n    return y","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:27:16.546574Z","iopub.execute_input":"2021-12-24T22:27:16.548001Z","iopub.status.idle":"2021-12-24T22:27:16.555538Z","shell.execute_reply.started":"2021-12-24T22:27:16.547932Z","shell.execute_reply":"2021-12-24T22:27:16.554251Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def build_model(include_top, num_classes, dropout_rate, name=None):\n    \n    inputs = Input(shape=Config.IMAGE_SIZE)\n\n    outputs = build_blocks(inputs)\n    \n    if include_top:\n        \n        outputs = top_block(outputs, num_classes, dropout_rate)\n\n    vgg16 = Model(inputs, outputs, name=name)\n    \n    return vgg16","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:29:04.862388Z","iopub.execute_input":"2021-12-24T22:29:04.863795Z","iopub.status.idle":"2021-12-24T22:29:04.877649Z","shell.execute_reply.started":"2021-12-24T22:29:04.863716Z","shell.execute_reply":"2021-12-24T22:29:04.876653Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# **Load Pretrained Weight**","metadata":{}},{"cell_type":"code","source":"CHECKPOINTS = {\n    'imagenet_no_top': ('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/'),\n    'imagenet_top': ('vgg16_weights_tf_dim_ordering_tf_kernels.h5', 'https://storage.googleapis.com/tensorflow/keras-applications/vgg16'),\n    'places365_no_top': ('vgg16-places365_weights_tf_dim_ordering_tf_kernels_notop.h5', 'https://github.com/GKalliatakis/Keras-VGG16-places365/releases/download/v1.0/'),\n    'places365_top': ('vgg16-places365_weights_tf_dim_ordering_tf_kernels.h5', 'https://github.com/GKalliatakis/Keras-VGG16-places365/releases/download/v1.0/')\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:29:05.349607Z","iopub.execute_input":"2021-12-24T22:29:05.349920Z","iopub.status.idle":"2021-12-24T22:29:05.355268Z","shell.execute_reply.started":"2021-12-24T22:29:05.349888Z","shell.execute_reply":"2021-12-24T22:29:05.354545Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def download_checkpoints(key):\n    \n    fname = CHECKPOINTS[key][0]\n    \n    url = f'{CHECKPOINTS[key][1]}/{fname}'\n    \n    download_path = io.download(url=url, fname=fname)\n    \n    return download_path","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:29:05.538578Z","iopub.execute_input":"2021-12-24T22:29:05.538891Z","iopub.status.idle":"2021-12-24T22:29:05.545679Z","shell.execute_reply.started":"2021-12-24T22:29:05.538860Z","shell.execute_reply":"2021-12-24T22:29:05.544488Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# **Export Model**","metadata":{}},{"cell_type":"code","source":"key = 'imagenet_no_top'\n\nvgg16 = build_model(include_top=False, num_classes=1000, dropout_rate=None)\n\ndownload_path = download_checkpoints(key)\n\nvgg16.load_weights(download_path)\n\nvgg16.save(f'vgg16_{key}.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:31:58.419763Z","iopub.execute_input":"2021-12-24T22:31:58.421155Z","iopub.status.idle":"2021-12-24T22:31:58.903645Z","shell.execute_reply.started":"2021-12-24T22:31:58.421110Z","shell.execute_reply":"2021-12-24T22:31:58.902319Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"key = 'imagenet_top'\n\nvgg16 = build_model(include_top=True, num_classes=1000, dropout_rate=None)\n\ndownload_path = download_checkpoints(key)\n\nvgg16.load_weights(download_path)\n\nvgg16.save(f'vgg16_{key}.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:31:58.905391Z","iopub.execute_input":"2021-12-24T22:31:58.905636Z","iopub.status.idle":"2021-12-24T22:32:02.205686Z","shell.execute_reply.started":"2021-12-24T22:31:58.905607Z","shell.execute_reply":"2021-12-24T22:32:02.204397Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"key = 'places365_no_top'\n\nvgg16 = build_model(include_top=False, num_classes=365, dropout_rate=0.5)\n\ndownload_path = download_checkpoints(key)\n\nvgg16.load_weights(download_path)\n\nvgg16.save(f'vgg16_{key}.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:32:02.209728Z","iopub.execute_input":"2021-12-24T22:32:02.210015Z","iopub.status.idle":"2021-12-24T22:32:02.653387Z","shell.execute_reply.started":"2021-12-24T22:32:02.209980Z","shell.execute_reply":"2021-12-24T22:32:02.651994Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"key = 'places365_top'\n\nvgg16 = build_model(include_top=True, num_classes=365, dropout_rate=0.5)\n\ndownload_path = download_checkpoints(key)\n\nvgg16.load_weights(download_path)\n\nvgg16.save(f'vgg16_{key}.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:32:02.655151Z","iopub.execute_input":"2021-12-24T22:32:02.655664Z","iopub.status.idle":"2021-12-24T22:32:06.910973Z","shell.execute_reply.started":"2021-12-24T22:32:02.655621Z","shell.execute_reply":"2021-12-24T22:32:06.910287Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}