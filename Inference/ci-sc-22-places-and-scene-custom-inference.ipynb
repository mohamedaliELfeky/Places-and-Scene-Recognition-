{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Modules**","metadata":{}},{"cell_type":"code","source":"import sys\n\nimport os\n\nimport random as pyrand\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nsys.path.insert(0, '../input/deeplearning-utils')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:39.532634Z","iopub.execute_input":"2021-12-20T08:39:39.532992Z","iopub.status.idle":"2021-12-20T08:39:39.538555Z","shell.execute_reply.started":"2021-12-20T08:39:39.532961Z","shell.execute_reply":"2021-12-20T08:39:39.537311Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from utils.ops import plot\n\nfrom utils.tf.ops import io, eval as tf_eval","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:40.242677Z","iopub.execute_input":"2021-12-20T08:39:40.243301Z","iopub.status.idle":"2021-12-20T08:39:46.768201Z","shell.execute_reply.started":"2021-12-20T08:39:40.243268Z","shell.execute_reply":"2021-12-20T08:39:46.763263Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:46.771882Z","iopub.execute_input":"2021-12-20T08:39:46.772626Z","iopub.status.idle":"2021-12-20T08:39:46.947911Z","shell.execute_reply.started":"2021-12-20T08:39:46.772584Z","shell.execute_reply":"2021-12-20T08:39:46.946701Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:46.962985Z","iopub.execute_input":"2021-12-20T08:39:46.963874Z","iopub.status.idle":"2021-12-20T08:39:46.976890Z","shell.execute_reply.started":"2021-12-20T08:39:46.963825Z","shell.execute_reply":"2021-12-20T08:39:46.975683Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras import backend, optimizers, regularizers\n\nfrom tensorflow.keras.layers import *\n\nfrom tensorflow.keras.models import Sequential, Model\n\n# from tensorflow.keras.applications import *\n\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:46.979173Z","iopub.execute_input":"2021-12-20T08:39:46.980416Z","iopub.status.idle":"2021-12-20T08:39:47.160192Z","shell.execute_reply.started":"2021-12-20T08:39:46.980360Z","shell.execute_reply":"2021-12-20T08:39:47.158860Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **Config**","metadata":{}},{"cell_type":"code","source":"def set_seed(tf_seed=0, np_seed=0, py_rand=0, py_hash=0):\n\n    os.environ['PYTHONHASHSEED'] = str(py_hash)\n    pyrand.seed(py_rand)\n\n    tf.random.set_seed(tf_seed)\n    np.random.seed(np_seed)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.502187Z","iopub.execute_input":"2021-12-20T08:39:51.502609Z","iopub.status.idle":"2021-12-20T08:39:51.511814Z","shell.execute_reply.started":"2021-12-20T08:39:51.502559Z","shell.execute_reply":"2021-12-20T08:39:51.510604Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"PATH = {'224': 'cisc22placesandscene224x224'}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.513724Z","iopub.execute_input":"2021-12-20T08:39:51.514130Z","iopub.status.idle":"2021-12-20T08:39:51.522693Z","shell.execute_reply.started":"2021-12-20T08:39:51.514088Z","shell.execute_reply":"2021-12-20T08:39:51.521772Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    SEED = 2053\n    \n    IMAGE_SIZE = (224, 224)\n\n    TRAIN_BATCH_SIZE = 32\n    VAL_BATCH_SIZE = 32\n        \n    SPLIT =10\n    \n    TRAIN_SIZE = None\n    \n    EPOCHS = 100\n    \n    TRAINING = False\n    \n    WINDOW_SIZE = 7\n    \n    CROP_SIZE = WINDOW_SIZE * WINDOW_SIZE","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.524579Z","iopub.execute_input":"2021-12-20T08:39:51.525001Z","iopub.status.idle":"2021-12-20T08:39:51.533592Z","shell.execute_reply.started":"2021-12-20T08:39:51.524958Z","shell.execute_reply":"2021-12-20T08:39:51.532517Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"set_seed(Config.SEED)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.538639Z","iopub.execute_input":"2021-12-20T08:39:51.539056Z","iopub.status.idle":"2021-12-20T08:39:51.545988Z","shell.execute_reply.started":"2021-12-20T08:39:51.539019Z","shell.execute_reply":"2021-12-20T08:39:51.544129Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"try:\n    \n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    \n    print('Running on TPU ', tpu.master())\n    \nexcept ValueError:\n  \n    tpu = None\n\nif tpu is not None:\n    \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nelse:\n    \n    strategy = tf.distribute.get_strategy()\n\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.548865Z","iopub.execute_input":"2021-12-20T08:39:51.550047Z","iopub.status.idle":"2021-12-20T08:39:51.565541Z","shell.execute_reply.started":"2021-12-20T08:39:51.550001Z","shell.execute_reply":"2021-12-20T08:39:51.563909Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"REPLICAS:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\n\nuser_secrets.set_tensorflow_credential(user_credential)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(PATH['224'])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:51.567295Z","iopub.execute_input":"2021-12-20T08:39:51.568644Z","iopub.status.idle":"2021-12-20T08:39:59.383288Z","shell.execute_reply.started":"2021-12-20T08:39:51.568599Z","shell.execute_reply":"2021-12-20T08:39:59.382291Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"augmentations = []\n\naugmentations.append(preprocessing.RandomFlip(mode='horizontal'))\naugmentations.append(preprocessing.RandomContrast(factor=0.8))\naugmentations.append(preprocessing.RandomRotation(factor=0.1, dtype=tf.float32))\n\naugmentations = Sequential(augmentations)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:59.384745Z","iopub.execute_input":"2021-12-20T08:39:59.385871Z","iopub.status.idle":"2021-12-20T08:39:59.713312Z","shell.execute_reply.started":"2021-12-20T08:39:59.385818Z","shell.execute_reply":"2021-12-20T08:39:59.712356Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data**","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\nignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:59.714769Z","iopub.execute_input":"2021-12-20T08:39:59.715263Z","iopub.status.idle":"2021-12-20T08:39:59.721616Z","shell.execute_reply.started":"2021-12-20T08:39:59.715220Z","shell.execute_reply":"2021-12-20T08:39:59.720335Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_rec = tf.io.gfile.glob(GCS_DS_PATH + '/train/train/*')\n\ntrain_rec = np.array(train_rec)\n\nprint(len(train_rec))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:39:59.723560Z","iopub.execute_input":"2021-12-20T08:39:59.723936Z","iopub.status.idle":"2021-12-20T08:40:00.487718Z","shell.execute_reply.started":"2021-12-20T08:39:59.723885Z","shell.execute_reply":"2021-12-20T08:40:00.486500Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"50\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_processing(x, y):\n        \n    x = tf.cast(x, dtype=tf.float32)\n    x /= 255.0\n    \n    y = tf.one_hot(y, depth=6)\n    \n    return augmentations(x, training=Config.TRAINING), y","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:00.489590Z","iopub.execute_input":"2021-12-20T08:40:00.490076Z","iopub.status.idle":"2021-12-20T08:40:00.496359Z","shell.execute_reply.started":"2021-12-20T08:40:00.490033Z","shell.execute_reply":"2021-12-20T08:40:00.495246Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def split_generator(train_idx, val_idx):\n    \n    dtype = {'image': 'bytes', 'label': 'int64'}\n    \n    reader = io.TfRecordReader(features_dtype=dtype,  image_key='image', \n                               tfrecord_shape=[*Config.IMAGE_SIZE, 3],  \n                               shape=None, channels=3,  func=None)\n    \n    train_data = tf.data.TFRecordDataset(train_rec[train_idx], num_parallel_reads=AUTOTUNE)\n    train_data = train_data.with_options(ignore_order)\n\n    train_data = train_data.map(reader.read_tfrecord, num_parallel_calls=AUTOTUNE)\n    train_data = train_data.batch(Config.TRAIN_BATCH_SIZE)\n    train_data = train_data.prefetch(AUTOTUNE)\n    train_data = train_data.map(train_processing)\n    \n    val_data = tf.data.TFRecordDataset(train_rec[val_idx], num_parallel_reads=AUTOTUNE)\n    val_data = val_data.with_options(ignore_order)\n\n    val_data = val_data.map(reader.read_tfrecord, num_parallel_calls=AUTOTUNE)\n    val_data = val_data.batch(Config.VAL_BATCH_SIZE)\n    val_data = val_data.prefetch(AUTOTUNE)\n    val_data = val_data.map(train_processing)\n    \n    return train_data, val_data","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:00.498536Z","iopub.execute_input":"2021-12-20T08:40:00.499472Z","iopub.status.idle":"2021-12-20T08:40:00.512524Z","shell.execute_reply.started":"2021-12-20T08:40:00.499426Z","shell.execute_reply":"2021-12-20T08:40:00.511308Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# sample_x, sample_y = split_generator(0, 1)[0].unbatch().as_numpy_iterator().next()\n\n# plt.imshow(sample_x)\n# plt.title(f'label = {int(sample_y.argmax())}')\n# plt.axis('off')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:00.514604Z","iopub.execute_input":"2021-12-20T08:40:00.515070Z","iopub.status.idle":"2021-12-20T08:40:00.527957Z","shell.execute_reply.started":"2021-12-20T08:40:00.515029Z","shell.execute_reply":"2021-12-20T08:40:00.526492Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"src_dir = '../input/ci-sc22-places-and-scene-recognition/'\n\ntest_path = tf.io.gfile.glob(src_dir + '/test_images/test_images/*')\n\nprint(len(test_path))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:00.530032Z","iopub.execute_input":"2021-12-20T08:40:00.530463Z","iopub.status.idle":"2021-12-20T08:40:03.895974Z","shell.execute_reply.started":"2021-12-20T08:40:00.530422Z","shell.execute_reply":"2021-12-20T08:40:03.894968Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"3407\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_test_example(i):\n    \n    image_name = os.path.split(test_path[i])[1]\n    \n    image = io.read_image(test_path[i])\n    image = tf.expand_dims(image, axis=0)\n    image = tf.image.resize(image, Config.IMAGE_SIZE)\n    image = tf.cast(image, dtype=tf.float32)\n    image /= 255.0\n    \n    return image_name, image","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.897554Z","iopub.execute_input":"2021-12-20T08:40:03.898043Z","iopub.status.idle":"2021-12-20T08:40:03.905188Z","shell.execute_reply.started":"2021-12-20T08:40:03.897998Z","shell.execute_reply":"2021-12-20T08:40:03.904138Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# **Utils**","metadata":{}},{"cell_type":"code","source":"class ExtractPatches(Layer):\n\n    def __init__(self, crop_size, *args, **kwargs):\n\n        self.crop_size = crop_size\n\n        super(ExtractPatches, self).__init__(*args, **kwargs)\n\n    def extract_patches(self, image, padding='SAME'):\n\n        channel_last = tf.transpose(image, perm=[2, 0, 1])\n        channel_last = channel_last[..., None]\n\n        patches = \\\n            tf.image.extract_patches(channel_last, sizes=[1, self.crop_size[0], self.crop_size[1], 1], padding=padding,\n                                     strides=[1, self.crop_size[0], self.crop_size[1], 1], rates=[1, 1, 1, 1])\n\n        patch_view = tf.transpose(patches, perm=[1, 2, 3, 0])\n\n        shape = tf.shape(patch_view)\n\n        num_patches = shape[0] * shape[1]\n        size = self.crop_size[0] * self.crop_size[1] * shape[3]\n\n        patch_view = \\\n            tf.reshape(patch_view, shape=(num_patches, size))\n\n        return patch_view\n\n    def get_outputs(self, patch_view, num_channels):\n        \n        patch_view = \\\n            tf.reshape(patch_view, shape=self.patch_view_shape(patch_view, num_channels))\n\n        return patch_view\n\n    def patch_view_shape(self, patch_view, num_channels):\n\n        shape = patch_view.shape\n\n        num_patches = shape[1]\n\n        view_shape = (-1, num_patches, self.crop_size[0], self.crop_size[1], num_channels)\n\n        return view_shape\n\n    def map_extract_patches(self, inputs):\n\n        outputs = tf.map_fn(self.extract_patches, inputs, fn_output_signature=inputs.dtype)\n\n        return outputs\n\n    def call(self, inputs, training=None):\n\n        shape = inputs.shape\n\n        num_channels = shape[-1]\n\n        outputs = self.map_extract_patches(inputs)\n\n        outputs = self.get_outputs(outputs, num_channels=num_channels)\n\n        return outputs\n    \n    def get_config(self):\n        \n        cfg = super(ExtractPatches, self).get_config()\n        \n        cfg['crop_size'] = self.crop_size\n        \n        return cfg","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.909251Z","iopub.execute_input":"2021-12-20T08:40:03.909977Z","iopub.status.idle":"2021-12-20T08:40:03.939244Z","shell.execute_reply.started":"2021-12-20T08:40:03.909929Z","shell.execute_reply":"2021-12-20T08:40:03.938063Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# sample_x, sample_y = split_generator(0, 1)[0].unbatch().as_numpy_iterator().next()\n\n# sample_x = tf.expand_dims(sample_x, axis=0)\n\n# sample_patches = ExtractPatches(crop_size=(Config.CROP_SIZE, Config.CROP_SIZE))(sample_x)\n# sample_patches = tf.squeeze(sample_patches, axis=0).numpy()\n\n# print(sample_patches.shape)\n\n# fig, axs = plot.plot(sample_patches, nrows=5, ncols=5, figsize=(5, 5))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.940997Z","iopub.execute_input":"2021-12-20T08:40:03.941361Z","iopub.status.idle":"2021-12-20T08:40:03.954008Z","shell.execute_reply.started":"2021-12-20T08:40:03.941318Z","shell.execute_reply":"2021-12-20T08:40:03.952898Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# **Build Model**","metadata":{}},{"cell_type":"code","source":"input_shape = (*Config.IMAGE_SIZE, 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.956816Z","iopub.execute_input":"2021-12-20T08:40:03.957842Z","iopub.status.idle":"2021-12-20T08:40:03.969181Z","shell.execute_reply.started":"2021-12-20T08:40:03.957753Z","shell.execute_reply":"2021-12-20T08:40:03.967843Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef accuracy_score(y_true, y_pred):\n    \n    y_true = backend.argmax(y_true, axis=-1)\n    y_pred = backend.argmax(y_pred, axis=-1)\n    \n    score = tf.equal(y_true, y_pred)\n    score = tf.cast(score, dtype=tf.float32)\n    \n    return backend.mean(score)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.972231Z","iopub.execute_input":"2021-12-20T08:40:03.972700Z","iopub.status.idle":"2021-12-20T08:40:03.982128Z","shell.execute_reply.started":"2021-12-20T08:40:03.972653Z","shell.execute_reply":"2021-12-20T08:40:03.980990Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def build_baseline_model():\n    \n    inputs = Input(shape=input_shape)\n    \n    # ===================================================================================\n\n    patches = ExtractPatches(crop_size=(Config.CROP_SIZE, Config.CROP_SIZE))(inputs)\n    \n    # ===================================================================================\n\n    proj = []\n    \n    for i in range(2):\n        \n        filters = 8\n        window_size = 2 * i + 1\n        \n        z = TimeDistributed(Conv2D(filters=filters, kernel_size=(window_size, window_size), padding='same'))(patches)\n        z = TimeDistributed(Activation('relu'))(z)\n        \n        proj.append(z)\n        \n    proj_skip = Add(name='proj_skip')(proj)\n        \n    # ===================================================================================\n\n    value = ConvLSTM2D(filters=128, kernel_size=(Config.WINDOW_SIZE, Config.WINDOW_SIZE), padding='same', \n                       strides=Config.WINDOW_SIZE, go_backwards=True, return_sequences=True, name='value')(proj_skip)\n    \n    \n    # ===================================================================================\n    \n    query = ConvLSTM2D(filters=6, kernel_size=(1, 1), name='query_logits', \n                       activation='tanh', go_backwards=True, return_sequences=True)(z)    \n    \n    # ===================================================================================\n    \n    attention = MultiHeadAttention(num_heads=6, key_dim=2, attention_axes=(2, 3), name='multi_head_attention')(query, value)\n    \n    # ===================================================================================\n\n    attention_pool = TimeDistributed(GlobalAvgPool2D(), name='attention_pool')(attention)\n        \n    # ===================================================================================\n\n    sequence_estimation = Bidirectional(LSTM(units=512), name='sequence_estimation')(attention_pool)\n    \n    # ===================================================================================\n    \n    y_logits = Dense(6, name='y_logits')(sequence_estimation)\n    y_proba = Activation('softmax', name='y_proba')(y_logits)\n    \n    # ===================================================================================\n\n    baseline_model = Model(inputs, y_proba)\n    \n    # ===================================================================================\n    \n    optimizer = optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999)\n    \n    loss = tf.losses.CategoricalCrossentropy(name='categorical_crossentropy')\n    \n    baseline_model.compile(optimizer=optimizer, loss=loss, metrics=accuracy_score)\n    \n    # ===================================================================================\n\n    return baseline_model","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:03.984428Z","iopub.execute_input":"2021-12-20T08:40:03.984884Z","iopub.status.idle":"2021-12-20T08:40:04.003555Z","shell.execute_reply.started":"2021-12-20T08:40:03.984836Z","shell.execute_reply":"2021-12-20T08:40:04.002285Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# build_baseline_model().summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:04.010679Z","iopub.execute_input":"2021-12-20T08:40:04.011044Z","iopub.status.idle":"2021-12-20T08:40:04.017602Z","shell.execute_reply.started":"2021-12-20T08:40:04.011011Z","shell.execute_reply":"2021-12-20T08:40:04.016590Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# **Load Model**","metadata":{}},{"cell_type":"code","source":"weights_path = tf.io.gfile.glob('../input/cisc22placesandscenev0models/*.h5')\n\nprint(len(weights_path))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:04.019022Z","iopub.execute_input":"2021-12-20T08:40:04.020060Z","iopub.status.idle":"2021-12-20T08:40:04.033895Z","shell.execute_reply.started":"2021-12-20T08:40:04.019926Z","shell.execute_reply":"2021-12-20T08:40:04.032839Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"kfold = KFold(n_splits=Config.SPLIT, shuffle=False)\n\n(train_idx, val_idx) = next(kfold.split(train_rec))\n\ntrain_data, val_data = split_generator(train_idx, val_idx)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:04.036770Z","iopub.execute_input":"2021-12-20T08:40:04.037088Z","iopub.status.idle":"2021-12-20T08:40:05.003010Z","shell.execute_reply.started":"2021-12-20T08:40:04.037063Z","shell.execute_reply":"2021-12-20T08:40:05.001968Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n\n    model = build_baseline_model()\n\nmodel.load_weights(weights_path[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:05.004872Z","iopub.execute_input":"2021-12-20T08:40:05.005287Z","iopub.status.idle":"2021-12-20T08:40:07.732849Z","shell.execute_reply.started":"2021-12-20T08:40:05.005215Z","shell.execute_reply":"2021-12-20T08:40:07.731503Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:07.734935Z","iopub.execute_input":"2021-12-20T08:40:07.735263Z","iopub.status.idle":"2021-12-20T08:40:07.758437Z","shell.execute_reply.started":"2021-12-20T08:40:07.735222Z","shell.execute_reply":"2021-12-20T08:40:07.757446Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nextract_patches (ExtractPatches (None, 25, 49, 49, 3 0           input_1[0][0]                    \n__________________________________________________________________________________________________\ntime_distributed_2 (TimeDistrib (None, 25, 49, 49, 8 224         extract_patches[0][0]            \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, 25, 49, 49, 8 32          extract_patches[0][0]            \n__________________________________________________________________________________________________\ntime_distributed_3 (TimeDistrib (None, 25, 49, 49, 8 0           time_distributed_2[0][0]         \n__________________________________________________________________________________________________\ntime_distributed_1 (TimeDistrib (None, 25, 49, 49, 8 0           time_distributed[0][0]           \n__________________________________________________________________________________________________\nproj_skip (Add)                 (None, 25, 49, 49, 8 0           time_distributed_1[0][0]         \n                                                                 time_distributed_3[0][0]         \n__________________________________________________________________________________________________\nquery_logits (ConvLSTM2D)       (None, 25, 49, 49, 6 360         time_distributed_3[0][0]         \n__________________________________________________________________________________________________\nvalue (ConvLSTM2D)              (None, 25, 7, 7, 128 3412480     proj_skip[0][0]                  \n__________________________________________________________________________________________________\nmulti_head_attention (MultiHead (None, 25, 49, 49, 6 3258        query_logits[0][0]               \n                                                                 value[0][0]                      \n__________________________________________________________________________________________________\nattention_pool (TimeDistributed (None, 25, 6)        0           multi_head_attention[0][0]       \n__________________________________________________________________________________________________\nsequence_estimation (Bidirectio (None, 1024)         2125824     attention_pool[0][0]             \n__________________________________________________________________________________________________\ny_logits (Dense)                (None, 6)            6150        sequence_estimation[0][0]        \n__________________________________________________________________________________________________\ny_proba (Activation)            (None, 6)            0           y_logits[0][0]                   \n==================================================================================================\nTotal params: 5,548,328\nTrainable params: 5,548,328\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"code","source":"# submission = pd.read_csv(src_dir + 'sample_submission.csv')\n\n# submission.drop([0, 1], axis=0, inplace=True)\n\n# for i in tqdm(range(len(test_path))):\n    \n#     image_name, image = read_test_example(i)\n    \n#     y = model.predict_on_batch(image).argmax(axis=-1)[0]\n    \n#     submission = submission.append({'image_name': image_name, 'label': y}, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:40:56.015073Z","iopub.execute_input":"2021-12-20T08:40:56.015428Z","iopub.status.idle":"2021-12-20T08:46:21.769943Z","shell.execute_reply.started":"2021-12-20T08:40:56.015382Z","shell.execute_reply":"2021-12-20T08:46:21.768049Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"100%|██████████| 3407/3407 [05:25<00:00, 10.46it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# submission.to_csv('submission.csv', index=False, encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:46:21.772763Z","iopub.execute_input":"2021-12-20T08:46:21.773211Z","iopub.status.idle":"2021-12-20T08:46:21.792044Z","shell.execute_reply.started":"2021-12-20T08:46:21.773134Z","shell.execute_reply":"2021-12-20T08:46:21.790893Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}